{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437a3e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "# from openai import AzureOpenAI  #? client.chat.completions.create\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#? Model should also have context about document to answer it more appropriately\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0eb828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['HF_TOKEN'] = os.getenv(\"HF_TOKEN\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['ENDPOINT_URL'] = os.getenv(\"ENDPOINT_URL\")\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ['AZURE_OPENAI_API_VERSION'] = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b795af8",
   "metadata": {},
   "source": [
    "##### Basic llmAzure Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"ENDPOINT_URL\"],\n",
    ")\n",
    "response = llm.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "    ],\n",
    ")\n",
    "print(json.dumps(response.to_dict(), indent=4))\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"ENDPOINT_URL\"],\n",
    ")\n",
    "llm.invoke(\"What is generative AI?\")\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "    (\"user\",\"{input}\")\n",
    "    ])\n",
    "prompt = ChatPromptTemplate.from_template(\"Question: {input}\")\n",
    "output_parser = StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967932e",
   "metadata": {},
   "source": [
    "##### GenAI App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef567d",
   "metadata": {},
   "source": [
    "##### MostBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c435bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=WebBaseLoader(\"https://docs.smith.langchain.com/observability/tutorials/observability\").load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "docs=text_splitter.split_documents(docs)\n",
    "texts = [doc.page_content for doc in docs]\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "vectorstoredb = FAISS.from_documents(docs, embeddings)\n",
    "# query=\"One Last part of the application we havent traced\"\n",
    "# result=vectorstoredb.similarity_search(query)\n",
    "# result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d075fb0",
   "metadata": {},
   "source": [
    "##### DocumentChain-->Retrieval Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e11c3909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith provides tools to trace the whole LLM pipeline, not just individual calls to the LLM. To trace the entire pipeline, you need to import from `langsmith` and use the `@traceable` decorator on the overall function. For example, if you call the function `rag(\"where did harrison work\")`, LangSmith will produce a trace of the entire pipeline including the OpenAI call as a child run.\\n\\nAdditionally, you will need to set environment variables to enable tracing, authenticate the API, and designate the project. Here are the relevant environment variables:\\n\\n- `LANGSMITH_TRACING=true`\\n- `LANGSMITH_API_KEY=<your-api-key>`\\n- `LANGSMITH_PROJECT=default`\\n\\nThese variables may be referenced as `LANGCHAIN_*` in other places, but `LANGSMITH_TRACING`, `LANGSMITH_API_KEY`, and `LANGSMITH_PROJECT` are considered the best practice. Ensure you\\'re using the appropriate versions of the SDK to support the `LANGSMITH_PROJECT` flag.\\n\\nTracing your LLM calls is straightforward with LangSmith\\'s OpenAI wrapper. All you need to do is modify your code accordingly to integrate this tracing functionality.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the following question based only on the provided context:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \"\"\")\n",
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"ENDPOINT_URL\"],\n",
    ")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain=create_retrieval_chain(vectorstoredb.as_retriever(),document_chain)\n",
    "response=retrieval_chain.invoke({\"input\":\"LangSmith has two usage limits: total traces and extended\"})\n",
    "response['answer']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d57244",
   "metadata": {},
   "source": [
    "##### LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ddfe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=os.environ['GROQ_API_KEY'])\n",
    "generic_template=\"Translate the following into {language}:\"\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",generic_template),(\"user\",\"{text}\")\n",
    "])\n",
    "human_query={\"language\":\"French\",\"text\":\"Hello\"}\n",
    "# prompt.invoke(human_query).to_messages()\n",
    "# messages=[\n",
    "#     SystemMessage(content=\"Translate the following from English to French\"),\n",
    "#     HumanMessage(content=\"Hello How are you?\")\n",
    "# ]\n",
    "parser=StrOutputParser()\n",
    "chain=prompt|model|parser\n",
    "response=chain.invoke(human_query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672ae4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
