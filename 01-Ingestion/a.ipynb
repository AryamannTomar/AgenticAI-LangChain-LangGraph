{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0579c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bs4\n",
    "import json\n",
    "import requests\n",
    "import tqdm as tqdm\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, WebBaseLoader, ArxivLoader, WikipediaLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter, HTMLHeaderTextSplitter, RecursiveJsonSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934178f6",
   "metadata": {},
   "source": [
    "##### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdc3449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs1=TextLoader('speech.txt').load()\n",
    "# docs2=PyPDFLoader('attention.pdf').load()\n",
    "# docs3=WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "#                      bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "#                          class_=(\"post-title\",\"post-content\",\"post-header\")\n",
    "#                      ))).load()\n",
    "# docs4= ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()\n",
    "# docs5= WikipediaLoader(query=\"Generative AI\", load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df488d6",
   "metadata": {},
   "source": [
    "##### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('speech.txt') as file:\n",
    "#     speech=file.read()\n",
    "# text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "# docs=text_splitter.create_documents([speech])\n",
    "\n",
    "# # docs=PyPDFLoader('attention.pdf').load()\n",
    "# # text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "# # f_docs=text_splitter.split_documents(docs)\n",
    "# # len(f_docs)\n",
    "\n",
    "# with open('speech.txt') as file:\n",
    "#     speech=file.read()\n",
    "# text_splitter=CharacterTextSplitter(separator='\\n\\n', chunk_size=100, chunk_overlap=20)\n",
    "# docs=text_splitter.create_documents([speech])\n",
    "\n",
    "# url = \"https://plato.stanford.edu/entries/goedel/\"\n",
    "# headers_to_split_on = [\n",
    "#     (\"h1\", \"Header 1\"),\n",
    "#     (\"h2\", \"Header 2\"),\n",
    "#     (\"h3\", \"Header 3\"),\n",
    "#     (\"h4\", \"Header 4\"),\n",
    "# ]\n",
    "# html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "# html_header_splits = html_splitter.split_text_from_url(url)\n",
    "\n",
    "# json_data=requests.get(\"https://api.smith.langchain.com/openapi.json\").json()\n",
    "# json_splitter=RecursiveJsonSplitter(max_chunk_size=300)\n",
    "# json_chunks=json_splitter.split_json(json_data)\n",
    "# docs=json_splitter.create_documents(texts=[json_data])\n",
    "# texts=json_splitter.split_text(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a68454",
   "metadata": {},
   "source": [
    "##### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9983d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# embeddings=(OllamaEmbeddings(model=\"llama2\"))\\ndocs=[\\n       \"Alpha is the first letter of Greek alphabet\",\\n       \"Beta is the second letter of Greek alphabet\", \\n]\\n# r1 = [embeddings.embed_query(doc) for doc in tqdm.tqdm(docs, desc=\"Embedding docs\")]   \\nr1 = embeddings.embed_query([docs]) #? Faster\\nembeddings = OllamaEmbeddings(model=\"mxbai-embed-large\") #TODO 1024 dimensions\\ntext = \"This is a test document.\"\\nquery_result = embeddings.embed_query(text)\\nquery_result\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  \n",
    "\n",
    "'''\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\") #TODO 3072 dimensions\n",
    "embeddings_1024=OpenAIEmbeddings(model=\"text-embedding-3-large\",dimensions=1024)\n",
    "text=\"This is a tutorial on OPENAI embedding\"\n",
    "query_result=embeddings_1024.embed_query(text)\n",
    "docs=TextLoader('speech.txt').load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "f_docs=text_splitter.split_documents(docs)\n",
    "db=Chroma.from_documents(f_docs,embeddings_1024)\n",
    "query=\"It will be all the easier for us to conduct ourselves as belligerents\"\n",
    "retrieved_results=db.similarity_search(query)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# embeddings=(OllamaEmbeddings(model=\"llama2\"))\n",
    "# docs=[\n",
    "#        \"Alpha is the first letter of Greek alphabet\",\n",
    "#        \"Beta is the second letter of Greek alphabet\", \n",
    "# ]\n",
    "# r1 = [embeddings.embed_query(doc) for doc in tqdm.tqdm(docs, desc=\"Embedding docs\")]   \n",
    "r1 = embeddings.embed_query([docs]) #? Faster\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\") #TODO 1024 dimensions\n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result\n",
    "'''\n",
    "\n",
    "'''\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "doc_embeddings = embeddings.embed_documents(docs)\n",
    "query = \"this is a test document\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a686ed9",
   "metadata": {},
   "source": [
    "##### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=TextLoader('speech.txt').load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=30)\n",
    "docs=text_splitter.split_documents(docs)\n",
    "embeddings=OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "# db=FAISS.from_documents(docs, embeddings)\n",
    "# '''\n",
    "# #TODO We Can convert vectorStore into a Retriever Class, allows it to use in Other LangChain methods\n",
    "# '''\n",
    "query='What does the speaker believe is the main reason the United States would enter the war?'\n",
    "# results=db.similarity_search(query)\n",
    "# retriever=db.as_retriever()\n",
    "# retriever.invoke(query)\n",
    "# db.similarity_search_with_score(query) #? L2 Score - Manhattan Distance\n",
    "# ev=embeddings.embed_query(query)\n",
    "# db.similarity_search_by_vector(ev)\n",
    "\n",
    "# db.save_local(\"faiss_index\")\n",
    "# db2=FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "# db2.similarity_search(query)\n",
    "\n",
    "\n",
    "# vectordb=Chroma.from_documents(documents=docs,embedding=embeddings, persist_directory=\"./chroma_db\")\n",
    "# vectordb.similarity_search(query)\n",
    "# db2=Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings)\n",
    "# db2.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e93c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
